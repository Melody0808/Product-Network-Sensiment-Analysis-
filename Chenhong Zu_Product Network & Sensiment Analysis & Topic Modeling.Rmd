---
title: "PM Project"
author: "Melody"
date: "4/11/2020"
output:
  html_document: default
  pdf_document: default
---

```{r}
library(readxl)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(reshape2)
library(data.table)
library(tidytext)
library(tidyr)
library(widyr)
library(ggraph)
library(igraph)
library(topicmodels)
```


```{r}
women <- read.csv("Womens Clothing E-Commerce Reviews.csv") 
```

```{r}
women_clothing <- women %>% 
  group_by(Clothing.ID) %>%
  summarize(N = n()) %>%
  arrange(desc(N))
```


```{r}
data("stop_words")
women$Review.Text<- as.character(women$Review.Text)
women_tidy <- women %>% unnest_tokens(word, Review.Text) %>% anti_join(stop_words)
c1078 <- subset(women, Clothing.ID == "1078") %>% unnest_tokens(word, Review.Text) %>% anti_join(stop_words)
c862 <- subset(women_tidy, Clothing.ID == "862")
```


```{r}
# normalize reviews based on their length and penalize terms (in their importance or weight) if it appears in most documents.

women_tfidf <- women_tidy %>% count(Clothing.ID, word, sort = TRUE) %>% 
  ungroup() %>% bind_tf_idf(word, Clothing.ID, n)
```

```{r}
women_tfidf %>% arrange(-tf_idf)
```

```{r}
women_tfidf %>% arrange(desc(tf_idf)) %>%
  top_n(15, tf_idf) %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = Clothing.ID)) + geom_col(show.legend = FALSE) + coord_flip()
```

```{r}
#unnest <- as.data.table(women %>% 
 # unnest_tokens(bigram, `Review.Text`, token = "ngrams", n = 2) %>% 
#  separate(bigram, c("word1", "word2"), sep = " ") %>% 
#  filter(!word1 %in% stop_words$word) %>%
#  filter(!word2 %in% stop_words$word) %>% 
#  unite(bigram, word1, word2, sep = " ", remove = FALSE))
```



```{r}
women_cors <- women_tidy %>% 
  count(Clothing.ID, word, sort = TRUE) %>% ungroup() %>%
  pairwise_cor(Clothing.ID, word, n, sort = TRUE)
women_cors
```

```{r}
# visualize the network between different clothing so we can see some products received similar reviews so they may have similar styles or certain popular elements. 

#personalized recommendation & trend prediction & product volumn

set.seed(2020)
women_cors %>% filter(correlation > 0.97) %>% 
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(alpha = correlation, width = correlation))+
  geom_node_point(size = 6, color = "lightblue") +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
```

```{r}
women_dtm <- women_tidy %>% 
  group_by(word) %>%
  mutate(word_total = n()) %>%
  ungroup() %>%
  filter(word_total > 50) %>%
  unite(document, Clothing.ID) %>%
  count(document,word) %>%
  cast_dtm(document, word, n)
```

```{r}
# use LDA (latent dirichlet allocation) algorithm to divide review text into topics
women_lda <- LDA(women_dtm, k=4, control = list(seed = 2020))
```
```{r}
# visualize the four topics this model extract based on the most frequent terms within it. 
women_lda %>%
  tidy() %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  scale_x_reordered()
```


```{r}
# sentiment analysis
contributions <- women_tidy %>% 
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(word) %>%
  summarize(occurences = n(),contribution = sum(value))
```

```{r}
# to see which words had the most effect on sentiment values overall
contributions %>%
  top_n(25, abs(contribution)) %>%
  mutate(word = reorder(word, contribution)) %>%
  ggplot(aes(word, contribution, fill = contribution > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip()
```

```{r}
women_bycloth <- women_tidy %>% count(Clothing.ID, word, sort = TRUE) %>% ungroup()
top_senti_words <- women_bycloth %>% inner_join(get_sentiments("afinn"), by = "word") %>%
  mutate(contribution = value * n /sum(n))
top_senti_words
```




```{r}
# sentiment analysis
c1094 <- subset(women, Clothing.ID == "1094") %>% unnest_tokens(word, Review.Text) %>% anti_join(stop_words)

contribution2 <- c1094 %>% 
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(word) %>%
  summarize(occurences = n(), contribution = sum(value))
```

```{r}
# to see which words had the most effect on sentiment values for cothing id = 1094
contribution2 %>%
  top_n(25, abs(contribution)) %>%
  mutate(word = reorder(word, contribution)) %>%
  ggplot(aes(word, contribution, fill = contribution > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip()
```


